{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import split_folders\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the working directory\n",
    "os.chdir('/Users/mariahhurt/Desktop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files: 0 files [00:00, ? files/s]\u001b[A\n",
      "Copying files: 104 files [00:00, 1039.21 files/s]\u001b[A\n",
      "Copying files: 359 files [00:00, 1263.50 files/s]\u001b[A\n",
      "Copying files: 618 files [00:00, 1492.65 files/s]\u001b[A\n",
      "Copying files: 840 files [00:00, 1654.95 files/s]\u001b[A\n",
      "Copying files: 1086 files [00:00, 1832.70 files/s]\u001b[A\n",
      "Copying files: 1278 files [00:00, 1398.21 files/s]\u001b[A\n",
      "Copying files: 1440 files [00:00, 1366.10 files/s]\u001b[A\n",
      "Copying files: 1670 files [00:00, 1555.59 files/s]\u001b[A\n",
      "Copying files: 1874 files [00:01, 1674.46 files/s]\u001b[A\n",
      "Copying files: 2097 files [00:01, 1807.89 files/s]\u001b[A\n",
      "Copying files: 2293 files [00:01, 1756.10 files/s]\u001b[A\n",
      "Copying files: 2517 files [00:01, 1877.10 files/s]\u001b[A\n",
      "Copying files: 2715 files [00:01, 1875.58 files/s]\u001b[A\n",
      "Copying files: 2910 files [00:01, 1840.66 files/s]\u001b[A\n",
      "Copying files: 3099 files [00:01, 1831.53 files/s]\u001b[A\n",
      "Copying files: 3286 files [00:01, 1720.53 files/s]\u001b[A\n",
      "Copying files: 3487 files [00:01, 1798.03 files/s]\u001b[A\n",
      "Copying files: 3671 files [00:02, 1579.33 files/s]\u001b[A\n",
      "Copying files: 3837 files [00:02, 1523.81 files/s]\u001b[A\n",
      "Copying files: 3995 files [00:02, 1495.96 files/s]\u001b[A\n",
      "Copying files: 4149 files [00:02, 1385.00 files/s]\u001b[A\n",
      "Copying files: 4361 files [00:02, 1545.04 files/s]\u001b[A\n",
      "Copying files: 4587 files [00:02, 1706.35 files/s]\u001b[A\n",
      "Copying files: 4778 files [00:02, 1669.81 files/s]\u001b[A\n",
      "Copying files: 4954 files [00:02, 1685.48 files/s]\u001b[A\n",
      "Copying files: 5155 files [00:02, 1768.29 files/s]\u001b[A\n",
      "Copying files: 5363 files [00:03, 1850.68 files/s]\u001b[A\n",
      "Copying files: 5472 files [00:03, 1759.90 files/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "#Use this function https://pypi.org/project/split-folders/\n",
    "#To split into training and validation data folders for each class\n",
    "split_folders.ratio('input', output=\"output\", seed=1337, ratio=(.8, .2)) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/mariahhurt/Desktop/output/train'\n",
    "val_dir = '/Users/mariahhurt/Desktop/output/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional base (feature extractor)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(13, 13, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Deep feed-forward classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 53,185\n",
      "Trainable params: 53,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4377 images belonging to 2 classes.\n",
      "Found 1095 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(13, 13), batch_size=20, class_mode='binary')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(13, 13), batch_size=20, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.6191 - acc: 0.7531 - val_loss: 0.5925 - val_acc: 0.7500\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.5801 - acc: 0.7546 - val_loss: 0.5836 - val_acc: 0.7500\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.5810 - acc: 0.7435 - val_loss: 0.5661 - val_acc: 0.7500\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.5460 - acc: 0.7611 - val_loss: 0.5424 - val_acc: 0.7500\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.5231 - acc: 0.7566 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.5019 - acc: 0.7545 - val_loss: 0.4746 - val_acc: 0.7820\n",
      "Epoch 7/50\n",
      " 53/100 [==============>...............] - ETA: 0s - loss: 0.4709 - acc: 0.7840"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
